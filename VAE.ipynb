{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca262a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import imageio \n",
    " \n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed16654",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab3ab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image,_), (test_images,_) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e7c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = train_image.reshape(train_image.shape[0], 28,28,1).astype('float32')\n",
    "test_images =test_images.reshape(test_images.shape[0], 28,28,1).astype('float32')\n",
    "\n",
    "# normalize the images to the range of [0...1]\n",
    "\n",
    "train_image/=255.\n",
    "test_images/=255.\n",
    "\n",
    "# Binarization\n",
    "train_image[train_image >= .5] =1\n",
    "train_image[train_image < .5] = 0\n",
    "test_images[test_images >= .5] =1\n",
    "test_images[test_images < .5] =0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "172c915c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a0e94fb490>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show image\n",
    "plt.imshow(train_image[9,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25048d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BUF = 60000\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "TEST_BUF = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "680b956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset =tf.data.Dataset.from_tensor_slices(train_image).shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images).shuffle(TEST_BUF).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f692970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution VAE class\n",
    "\n",
    "class CVAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.inference_net = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(28,28,1)),\n",
    "            tf.keras.layers.Conv2D( filters=32, kernel_size=3, strides=(2,2), activation='relu'),\n",
    "            tf.keras.layers.Conv2D( filters=64, kernel_size=3, strides=(2,2), activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            \n",
    "            # no activation\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "        ]\n",
    "            )\n",
    "        \n",
    "        self.generative_net = tf.keras.Sequential(\n",
    "            [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(7,7,32)),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3,strides=(2,2),padding=\"SAME\",activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3,strides=(2,2),padding=\"SAME\",activation='relu'),\n",
    "            \n",
    "            # no activation\n",
    "            tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3,strides=(1,1),padding=\"SAME\"),\n",
    "        ])\n",
    "        \n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mean,logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5)\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.generative_net(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89757eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cff60932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(-.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),axis=raxis)\n",
    "\n",
    "@tf.function\n",
    "def compute_loss(model, x):\n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = model.decode(z)\n",
    "\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = log_normal_pdf(z, 0., 0.)\n",
    "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a233ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_apply_gradients(model, x, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2134c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "latent_dim = 50\n",
    "model = CVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e1eb542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the random vector constant for generation (prediction) so # it will be easier to see the improvement.\n",
    "num_examples_to_generate = 16\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bc752c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model.sample(test_input)\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    # tight_layout minimizes the overlap between 2 sub-plots\n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cef569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_and_save_images(model, 0, random_vector_for_generation)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for train_x in train_dataset:\n",
    "        compute_apply_gradients(model, train_x, optimizer)\n",
    "    end_time = time.time()\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        \n",
    "        loss = tf.keras.metrics.Mean()\n",
    "        for test_x in test_dataset:\n",
    "            loss(compute_loss(model, test_x))\n",
    "        elbo = -loss.result()\n",
    "        \n",
    "        display.clear_output(wait=False)\n",
    "        print('Epoch: {}, Test set ELBO: {}, '\n",
    "              'time elapse for current epoch {}'.format(epoch,\n",
    "                                                        elbo,\n",
    "                                                        end_time - start_time))\n",
    "        \n",
    "        generate_and_save_images(model, epoch, random_vector_for_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d75d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(display_image(epochs))\n",
    "plt.axis('off')# Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'cvae.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        frame = 2*(i**0.5)\n",
    "        if round(frame) > round(last):\n",
    "            last = frame\n",
    "        else:\n",
    "            continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "if IPython.version_info >= (6,2,0,''):\n",
    "    display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf5bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
